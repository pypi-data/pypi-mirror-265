import backoff
import os
import together
import openai

from garak import _config
from .base import Agent


class TogetherAPI(Agent):
    """
    Agent that uses Together APIs to generate text.
    """

    # stream = True
    generator_family_name = "Together"

    def __init__(self, name, generations: int = 10):
        """
        Initialize the `TogetherAPI` object with a name and number of generations.
        
        Parameters
        ----------
        name : str
            name of the LLM to use.
        generations : int
            number of generations to run.
        """
        # def __init__(self, name, config: AgentConfig=None):

        if hasattr(_config.run, "seed"):
            self.seed = _config.run.seed

        self.family = "Together"
        super().__init__(name, generations)

        token_name = "TOGETHER_API_TOKEN"
        if token_name not in os.environ:
            raise ValueError(
                f'''Put the Together API token in the {token_name} environment variable\n \
                e.g.: export {token_name}="esecret_1234567890abcdefg"'''
            )
        together.api_key = os.getenv("TOGETHER_API_TOKEN")
        self.agent = together.Complete

    @backoff.on_exception(
        backoff.fibo,
        (
            openai.BadRequestError,
            openai.AuthenticationError,
            openai.PermissionDeniedError,
            openai.NotFoundError,
            openai.UnprocessableEntityError,
            openai.RateLimitError,
            openai.InternalServerError,
            openai.APIConnectionError,
        ),
        max_value=70,
    )
    def _call_model(self, prompt):
        """
        Generate response(s) for a given prompt.
        
        Parameters
        ----------
        prompt : str
            prompt to generate response for.
            
        Returns
        -------
        str
            response generated by the model.
        """
        try:
            response = self.agent.create(
                model=self.name,
                prompt=prompt,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                top_k=self.top_k,
                # stream=self.stream
            )["output"]["choices"][0]["text"].strip()
        except:
            response = ""
        return response


default_class = "TogetherAPI"
