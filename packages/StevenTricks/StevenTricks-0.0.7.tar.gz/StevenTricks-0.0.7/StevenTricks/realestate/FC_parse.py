# -*- coding: utf-8 -*-
"""
Created on Mon Sep 21 09:47:12 2020

@author: 118939
"""

import re

import pandas as pd
import pdfplumber
from multiprocessing import Pool
from sys import exc_info
from os import path
from StevenTricks import db_path
from StevenTricks.fileop import PathWalk_df
from pdfminer.pdfparser import PDFSyntaxError
from StevenTricks import db_sqlite as db

db_path = path.join(db_path, 'ForeClosure')
key_dict = {
    '凶宅': ["自殺", "上吊", "燒炭", "命案", "非自然死亡", "非自然身故", "為凶宅", "死於", '凶宅'],
    '海砂屋': ["為海砂屋", '氯離子含量高於標準', '高氯離子', '海砂屋可能性較高', '核備屬高氯離子'],
    '輻射屋': ["為輻射", "列管中", "管制中", "原子能", "輻射過量", "輻射超標", "列冊管理", "列冊", '輻射汙染'],
    '火災受損屋': ['撲滅', '曾發生火災'],
    '地震受損屋': ['有地震受損', '因地震而', '另因地震'],
    '神壇': ["宮廟"],
    '產權瑕疵': ['未直接臨路', '產權不清'],
    '其他': ["爛尾", "中輟", "事故", '外露', '裂痕', '危樓', '裸露']
}
skip_key_list = ['嚴重漏水、火災受損、建物內有非自然死亡', '均無地震受損、火災受損、漏水、非自然死亡之情形', '火災受損、建物內有非自然死亡或其他足以影響交易', '輻射屋、地震受創、火災受損、非自然死亡之情事。', '輻射、地震受創、火災受損或非自然死亡等影響交易價額情形', '查無海砂、輻射、地震受創、火災受損或非自然死亡等影響交易價', '無海砂屋、輻射屋、地震受創、火災受損、非自然死亡等情事。', '有無海砂屋、地震或火災受創及建物內有非自然死亡等足以影響交易之特殊情事', '沒有聽聞有海砂屋、輻射屋、非自然死亡、嚴重漏水等足以影響交易之重大情形。', '是否為海砂屋，建請洽專業機構人員辦理相關鑑定為宜', '經初步調查無海砂屋、輻射屋', '並無輻射屋、地震受創、火災受損、非自然死亡等情形。', '查詢台灣凶宅網網站，未查得', '例如：建物內前有非自然死亡情事、海砂屋、輻射屋、', '海砂屋、輻射屋、地震受創、火災受損、非自然死亡等情形。', '並無發生非自然死亡情形，亦無發生過火災', '輻射屋、地震受創、火災受創、建物內有非自然死亡等之狀況', '受創、火災受損、嚴重漏水', '、地震受創、火災受損或非自然死亡', '包含是否為海砂屋、輻射屋、凶宅、危樓', '水、火災受損、建物內有非自然死亡或其他足以影響交', '地震受創、火災受損、建物內有非自然死亡等情形', '無地震受創、無嚴重漏水、無火災受損、無非自然死亡情事', '，未發現有非自然死亡情事', '，亦無非自然死亡、輻射屋等情事', '海砂屋、輻射屋、地震受創、非自然死亡', '未建構非自然死亡案件', '輻射屋、地震受創、火災受損及建物內有非自然死亡', '稱凶宅、海砂屋、輻射屋、地震受創、火災受損', '嚴重漏水、火災受損、建物內有無非自然死亡', '海砂屋、輻射屋、凶宅', '皆無非自然死亡', '火災、非自然死亡、地震受創、海砂輻射', '輻射屋、地震或火災受創及建物內有非自然死亡', '未曾聽聞有發生過非自然死亡', '未聞有非自然死亡', '受創、嚴重漏水、火災受損', '無發現有火災受損', '未發現有凶宅', '是否有非自然死亡', '查無凶宅、火災受損等情', '輻射、地震受創、嚴重漏水、火災、凶宅', '無印象有輻射屋或非自然死亡', '海沙屋、輻射屋、地震受創、', '建物有無非自然死亡情形', '未有非自然死亡', '、火災受損或有人非自然死亡', '海砂屋、輻射屋、建物內有非自然死亡', '無漏水、火災、輻射及非自然死亡', '無火災、地震受創、漏水等非自然死亡', '輻射屋、地震、或火災受創及建物內有非自然死亡', '無發生非自然死亡、火災受損、輻射屋、海砂屋、地震受創', '無海砂屋、輻射屋、地震受創、嚴重漏水及非自然死亡', '查無非自然死亡、非輻射屋', '無海砂屋、輻射屋、建物內有非自然死亡', '查無輻射屋及非自然死亡相關資料', '無地震、漏水、火災、非自然死亡', '本案建物不在台灣凶宅網提供之凶宅訊息', '函覆未發生非自然死亡情事', '輻射屋、地震受創、火災受損、建物內有非自然死亡', '水、火災受損或有人非自然死亡', '沒有地震受損、非自然死亡', '建物內無非自然死亡', '、輻射屋、地震受創、火災受 損、建物內有非自然死亡等情形', '查詢是否曾發生非自然死亡、火災受損、地震受損、', '陳述之真實度，查證上確有困難', '是否發生過非自然死亡案件，無資料可查', '無海砂屋、輻射屋、非自然死亡', '，未聽說有非自然死亡情事，', '未發現有非自然死亡情事，', '，無火災及大型地震受損過，無非自然死亡之情形，亦非輻射屋。', '無聽聞有輻射屋、地震受創、火災受損、非自然死亡', '是否建物內有非自然死亡之現象，', '印象中無非自然死', '，無火災、水災、輻射屋及非自然身故等情', '是否為海砂屋應以專業技師現場', '是否為海砂屋部分，現勘時觀察標的並無', '是否為輻射屋部分，利用', '，亦無增建、漏水、壁癌等情事。', '凶宅網無明確顯示', '無非自然死亡情形；非海砂、輻射屋；未因地震受創', '例如：建物內前有非自然死亡情事、輻射屋、因地震受創、', '無法確保拍賣標的至拍定時均不會再發生新非自然死亡、火災受損、地震受損', '查詢是否曾發生非自然死亡、火災受損、地震受損、', '回覆無非自然死亡記錄', '查無海砂屋、輻射屋、地震受創、火災受損及非自然死亡', '印象中標的物無非自然死亡之現象', '無地震受創、火災受創及非自然死亡等', '，未聽說有非自然死亡情事', '是否建物內有非自然死亡之現象：', '、輻射屋、地震、火災受創及建物內有非自然死亡', '非自然死亡案件，尚無', '未聽聞建物內有非自然死亡事件', '應無非自然死亡情事，惟實際情形應買人應自行查證，', '，就非自然死亡一節查無資料可稽', '未查詢到本件標的有非自然死亡情形', '函覆，無非自然死亡之紀錄', '例如：建物內前有非自然死亡情事、海砂屋、輻射', '無漏水、無壁癌、無非自然死亡之情形，亦無火災及地震受損', '海砂屋、輻射屋、地震受創、火災受損、非自然死亡', '非輻射屋、海砂屋，但有無非自然死亡或地震後受創、房屋傾斜等情事則不明', '無地震嚴重受損，或非自然死亡之情形等語。請應買人綜合考量相關風險', '、建物內有非自然死亡（如凶宅）等情並不清楚', '沒有發現有海砂屋、輻射屋、火災受損、非自然死亡等情形', '海砂屋、輻射屋、地震受創、火災受損、非自然死亡', '該建物無嚴重影響交易價額諸如凶宅、輻射、海砂屋', '無發生火災受損、漏水、非自然死亡、地震受創之紀錄，', '，或新檢測為海砂屋等，', '，亦無法保證本件建物絕對不會發生漏水', '未進入室內履勘，其室內維護', '就建物是否為海砂屋進行鑑定，', '是否為海砂屋、輻射屋、地震受創、火災受損、', '相關鑑定及偵測始能確認是否為海砂屋、有無輻射', '、火災受損、地震受損、是否曾檢測為海砂屋、輻射屋', '採樣檢測氯離子含量後方可判定是否為海砂屋；是否為輻射屋', '是否為海砂屋：現勘時觀察標的並無鋼筋腐蝕水泥脫落', '機構人員辦理相關鑑定為宜。', '經查詢市政府、原子能委員會及現場外觀觀察，查無海砂屋、輻射', '輻射屋部分：鑑估標的不在行政院原子能委員會網站查詢範圍內', '；且根據行政院原子能委員會截至目前偵測及評估結果，所有已經', '行政院原子能委員會函覆該建物未包含於該會放射性污染', '；經行政院原子能委員會', '，僅以外觀現況判斷；又經查詢行政院原子能委員會輻射屋查詢網、台灣兇宅網等網站', '無發現有嚴重漏水、火災之情事，查詢原子能委員會及台灣凶宅網查無輻射屋及非自然', '有關輻射屋部分，經詢問行政院原子能委員會，其表示該會截至目前偵測及評估', '，經查詢市政府、原子能委員會及現場外觀查詢，應無海砂屋、輻射屋', '行政院原子能委員會函覆系爭建物未包含於放射性污染', '之情形，但不知道是否為輻射鋼筋屋等語。', '易之特殊情事（例如：建物', '但非輻射屋、海砂屋，惟有無非自然死亡或因地震後受創、房屋傾斜等情事則不明', '亦無申請為新北市高氯離子鋼筋混凝土建築物紀錄', '：是否為海砂屋、輻射屋、地震受創、火災受損無法', '；嚴重漏水部分，勘察外觀尚無發現有漏水之情事，', '，狀況有改善，', '所造成之明顯混凝土剝落情況，及地震受創、火災受損之情事，', '故本件標的是否為海砂屋，建請洽專業機構人員辦理', '本件建物非屬行政院原子能委員會網站所示輻射屋清單內', '昭北府宮廟', '公尺處，其上有福德宮廟', '，是否為輻射屋應以專業技師現場採樣檢測方可判定，', '經查詢市政府、原子能委員會及現場外觀，查無海砂屋、輻射屋', '但無明顯漏水、火災痕跡', '查並未入室，無法得之勘估標的內部是否有嚴重漏水、', '、輻射屋、因地震受創、因火災受損、嚴重漏水、', '海砂屋、輻射屋、嚴重漏水、因地震受創', '、因火災受損、嚴重漏水、或其他情形）', '，無繼續使用之痕跡', '處理好，現在不會漏水。', '、因地震受創、因火災受損、或其他情形）', '未看到有漏水、壁癌等情形，', '、亦無申請為高氯離子鋼筋混凝土建築物', '是否為海砂屋、輻射屋、地震受創、火災受損無', '，無地震受創或漏水等痕跡，', '經檢視屋內情況，無漏水痕跡', '海砂屋、輻射屋部分，經查詢原子能委員會所登錄之放射性污染建築物', '原所有權人係於車上燒炭自殺', '查復無發生非自然死亡、火災受損、海砂屋、輻射屋、地震受創', '查無該社區海砂屋或牆面水泥剝落情況', '並無因地震受創或火災受損有明顯傾斜、裂痕或煙燻等狀況', '使用情形正常，無嚴重漏水或受損情況', ' 亦查無相關凶宅資訊，應無非自然死亡', '拍定人不得以物之瑕疵（如：建物內有非自然死亡', '經查詢市政府、原子能委員會及現場外觀查詢，應無海砂屋', '網路查詢並無非自然死亡相關訊息，', '本件建物自原子能委員會網站及建物外觀觀之，查無輻射屋', '、地震受創、火災受損、屋內漏水及建物內非自然死亡部分，未入內勘查', '原子能委員會，查無建物有輻射屋之紀錄', '自外觀目測無明顯鋼筋外露及地震火災毀損', '，並無海砂屋、輻射屋、嚴重漏水、火災受損', '，本件建物查無凶宅、火災受損等資料，然因本院欠缺完整', '無海砂屋、輻射屋、地震或火災受創、嚴重漏水及非自然死亡', '、輻射屋、地震或火災受創、嚴重漏水及非自然死亡', '函復查無非自然死亡刑事勘查紀錄，', '高氯離子鋼筋混凝土建築物申請報備案件清冊中，尚', '行政院原子能委員會函覆，該建物未包含於該會放射性污', '所造成之明顯混擬土剝落情形，及地震受創、火災受損之情事，', '未發現有非自然死亡案件(自殺、他殺)紀錄資料', '，惟無火災及非自然身故之情事。依強制執行法第69條之規定', '地震受損建築物，且非該處列管高氯離子混凝土建築物。', '實地調查詢問未發現有非自然死亡情事', '陳報無非自然死亡之情事', '未發現有非自然死亡情形', '、非海沙屋、非為地震受創危樓、非受有火災損害', '有非自然死亡情事；經新北市政府工務局', '，並提供氯離子含量試驗報告', '是否為高氯離子鋼筋混凝土建築物，建請洽專業機構', '本件建物經查詢原子能委員會及新北市政府，查無輻射屋及海', '、火災受損、地震受損事件，或新檢測為海砂屋、輻射屋', '高氯離子鋼筋混凝土建築物申請報備案件清冊中，無', '未包含於原子能委員會放射性污染建築物偵測紀錄中', '系統並無列管，是否為輻射屋應以專業技師現場採樣檢測輻射劑量後', '高氯離子鋼筋混凝土建築物網站未顯示本標的為高氯離', '查詢行政院原子能委員會網站未顯示本標的為輻射屋。', '，從裡面看無鋼筋外露情形。', '、非為地震受創之危樓、非受有火災損害之情事、無', '行政院原子能委員會稱該建物未包含於該會放射性污染']


def text_parse(filepath, page_skip_kw=[r'附表：'], page_skip_n=[], start=False, text_length=20):
    res_dict = {'filepath': filepath, 'filename': path.split(filepath)[1], 'error': None}
    try:
        with pdfplumber.open(filepath) as pdf:
            for page in pdf.pages:
                if page.page_number in page_skip_n:
                    continue

                text = page.extract_text()

                if re.search('|'.join(page_skip_kw), text) is not None:
                    start = True

                if start is False:
                    continue

                # 進入迭代關鍵字，開始查找關鍵字
                for typ, key_list in key_dict.items():
                    for key in key_list:
                        res_iter = re.finditer(key, text)

                        for res in res_iter:
                            text_start = res.span()[0]-text_length
                            if text_start < 0:
                                text_start = 0
                            text_piece = text[text_start: res.span()[1]+text_length]

                            # 檢查是否在排除字串內
                            if re.search('|'.join(skip_key_list), text_piece.replace('\n', '')) is None:
                                if typ not in res_dict:
                                    res_dict[typ] = []
                                res_dict[typ].append(text_piece)
                            else:
                                continue

        # 要輸出之前把所有的項目都弄成字串
        for typ in key_dict:
            if typ in res_dict:
                res_dict[typ] = str(res_dict[typ])

    except PDFSyntaxError:
        res_dict['error'] = str(exc_info())
    return res_dict


if __name__ == '__main__':
    # 先把素材抓出來
    cro = db.readsql_iter(r'D:\database\CrossWalk.db', table_list=['adm', 'plstre'])
    adm = next(cro)
    plstre = next(cro)
    # 先把所有檔案路徑抓出來、並且更改column名稱
    pdf_df = PathWalk_df(path.join(db_path, 'pdf'))
    pdf_df = pdf_df.loc[:, ['file', 'path']].rename(columns={'file': 'crm'})
    pdf_df['crm'] = pdf_df['crm'].str.rsplit('.', expand=True)[0]

    # 再把所有法拍資料抓出來，並且補上NLP_check這個欄位
    fc_df = pd.concat(list(db.readsql_iter(db_path)))
    fc_df = fc_df.drop_duplicates(subset=['crm', 'GUSTRE'])

    if 'NLP_check' not in fc_df:
        fc_df.loc[:, 'NLP_check'] = None
    fc_df = fc_df.loc[fc_df['NLP_check'].isnull()]
    fc_df = pd.merge(fc_df, adm.loc[:, ['TOWNCODE', 'COUNTYCODE']], on=['TOWNCODE'])
    plstre = plstre.fillna('')
    fc_df = pd.merge(fc_df, plstre, on=['COUNTYCODE', 'TOWNNAME', 'PLSTRENAME', 'PLSTRESECTION'], how='left')
    # a=fc_df.loc[fc_df.duplicated(subset=['ID'])]
    # a.to_csv(r'C:\Users\118939\Desktop\ddd.csv', encoding='utf-8')
    # fc_df = pd.merge(fc_df, pdf_df, on=['crm'], how='left')
    # fc_df = fc_df.drop_duplicates(subset=['crm'])

    output = pd.DataFrame()

    with Pool() as pool:
        for res in pool.imap_unordered(text_parse, pdf_df['path']):
            print(res['filename'], res['error'])
            output = pd.concat([output, pd.DataFrame(res, index=[0])], ignore_index=True, copy=False)
            print(output.shape)
            # if output.shape[0] > 3000:
            #     break

    output['crm'] = output['filename'].str.rsplit('.', expand=True)[0]
    fc_df = pd.merge(fc_df, output.drop(labels=['filepath', 'filename'], axis=1), on=['crm'], how='left')

    print(fc_df)
    print(fc_df.dtypes)
    print(plstre.dtypes)
    # plstre['COUNTYCODE'] = plstre['COUNTYCODE'].astype(str).str.rsplit('.', expand=True)[0]

    print(fc_df)
    with pd.ExcelWriter(r'C:\Users\118939\Desktop\fc_test.xlsx') as writer:
        fc_df.to_excel(writer, index=False)