from typing import List

def word_tokenize(text: str, language: str) -> List[str]: ...
def sent_tokenize(text: str, language: str) -> List[str]: ...
