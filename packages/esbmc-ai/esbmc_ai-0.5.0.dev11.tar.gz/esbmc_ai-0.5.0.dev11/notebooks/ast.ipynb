{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "tags": []
            },
            "source": [
                "# Test LLVM AST Notebook\n",
                "\n",
                "## Author: Yiannis Charalambous\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from clang.cindex import Config\n",
                "import clang.native\n",
                "import clang.cindex\n",
                "import sys\n",
                "from typing import NamedTuple\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Connect the Python API of Clang to the libclang.so file bundled in the libclang PyPI package.\n",
                "Config.library_file = os.path.join(\n",
                "    os.path.dirname(clang.native.__file__),\n",
                "    \"libclang.so\",\n",
                ")\n",
                "\n",
                "module_path = os.path.abspath(os.path.join(\"..\"))\n",
                "if module_path not in sys.path:\n",
                "    sys.path.append(module_path)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found a [line=4, col=5]\n",
                        "  Token int TokenKind.KEYWORD\n",
                        "  Token a TokenKind.IDENTIFIER\n",
                        "Start: 42, End: 47, Range: 5\n",
                        "\n",
                        "Found b [line=4, col=8]\n",
                        "  Token int TokenKind.KEYWORD\n",
                        "  Token a TokenKind.IDENTIFIER\n",
                        "  Token , TokenKind.PUNCTUATION\n",
                        "  Token b TokenKind.IDENTIFIER\n",
                        "Start: 42, End: 50, Range: 8\n",
                        "\n",
                        "Found __VERIFIER_atomic_acquire [line=5, col=6]\n",
                        "  Token void TokenKind.KEYWORD\n",
                        "  Token __VERIFIER_atomic_acquire TokenKind.IDENTIFIER\n",
                        "  Token ( TokenKind.PUNCTUATION\n",
                        "  Token void TokenKind.KEYWORD\n",
                        "  Token ) TokenKind.PUNCTUATION\n",
                        "  Token { TokenKind.PUNCTUATION\n",
                        "  Token __VERIFIER_assume TokenKind.IDENTIFIER\n",
                        "  Token ( TokenKind.PUNCTUATION\n",
                        "  Token a TokenKind.IDENTIFIER\n",
                        "  Token == TokenKind.PUNCTUATION\n",
                        "  Token 0 TokenKind.LITERAL\n",
                        "  Token ) TokenKind.PUNCTUATION\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token a TokenKind.IDENTIFIER\n",
                        "  Token = TokenKind.PUNCTUATION\n",
                        "  Token 1 TokenKind.LITERAL\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token } TokenKind.PUNCTUATION\n",
                        "Start: 52, End: 134, Range: 82\n",
                        "\n",
                        "Found c [line=10, col=7]\n",
                        "  Token void TokenKind.KEYWORD\n",
                        "  Token * TokenKind.PUNCTUATION\n",
                        "  Token c TokenKind.IDENTIFIER\n",
                        "  Token ( TokenKind.PUNCTUATION\n",
                        "  Token void TokenKind.KEYWORD\n",
                        "  Token * TokenKind.PUNCTUATION\n",
                        "  Token arg TokenKind.IDENTIFIER\n",
                        "  Token ) TokenKind.PUNCTUATION\n",
                        "  Token { TokenKind.PUNCTUATION\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token __VERIFIER_atomic_acquire TokenKind.IDENTIFIER\n",
                        "  Token ( TokenKind.PUNCTUATION\n",
                        "  Token ) TokenKind.PUNCTUATION\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token b TokenKind.IDENTIFIER\n",
                        "  Token = TokenKind.PUNCTUATION\n",
                        "  Token 1 TokenKind.LITERAL\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token return TokenKind.KEYWORD\n",
                        "  Token NULL TokenKind.IDENTIFIER\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token } TokenKind.PUNCTUATION\n",
                        "Start: 135, End: 224, Range: 89\n",
                        "\n",
                        "Found d [line=17, col=11]\n",
                        "  Token pthread_t TokenKind.IDENTIFIER\n",
                        "  Token d TokenKind.IDENTIFIER\n",
                        "Start: 225, End: 236, Range: 11\n",
                        "\n",
                        "Found main [line=18, col=5]\n",
                        "  Token int TokenKind.KEYWORD\n",
                        "  Token main TokenKind.IDENTIFIER\n",
                        "  Token ( TokenKind.PUNCTUATION\n",
                        "  Token ) TokenKind.PUNCTUATION\n",
                        "  Token { TokenKind.PUNCTUATION\n",
                        "  Token pthread_create TokenKind.IDENTIFIER\n",
                        "  Token ( TokenKind.PUNCTUATION\n",
                        "  Token & TokenKind.PUNCTUATION\n",
                        "  Token d TokenKind.IDENTIFIER\n",
                        "  Token , TokenKind.PUNCTUATION\n",
                        "  Token 0 TokenKind.LITERAL\n",
                        "  Token , TokenKind.PUNCTUATION\n",
                        "  Token c TokenKind.IDENTIFIER\n",
                        "  Token , TokenKind.PUNCTUATION\n",
                        "  Token 0 TokenKind.LITERAL\n",
                        "  Token ) TokenKind.PUNCTUATION\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token __VERIFIER_atomic_acquire TokenKind.IDENTIFIER\n",
                        "  Token ( TokenKind.PUNCTUATION\n",
                        "  Token ) TokenKind.PUNCTUATION\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token if TokenKind.KEYWORD\n",
                        "  Token ( TokenKind.PUNCTUATION\n",
                        "  Token ! TokenKind.PUNCTUATION\n",
                        "  Token b TokenKind.IDENTIFIER\n",
                        "  Token ) TokenKind.PUNCTUATION\n",
                        "  Token assert TokenKind.IDENTIFIER\n",
                        "  Token ( TokenKind.PUNCTUATION\n",
                        "  Token 0 TokenKind.LITERAL\n",
                        "  Token ) TokenKind.PUNCTUATION\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token return TokenKind.KEYWORD\n",
                        "  Token 0 TokenKind.LITERAL\n",
                        "  Token ; TokenKind.PUNCTUATION\n",
                        "  Token } TokenKind.PUNCTUATION\n",
                        "Start: 238, End: 363, Range: 125\n",
                        "\n",
                        "Total 6\n"
                    ]
                }
            ],
            "source": [
                "FILE = \"../samples/threading.c\"\n",
                "\n",
                "\n",
                "def get_declarations_local(root: clang.cindex.Cursor) -> list[clang.cindex.Cursor]:\n",
                "    declarations: list[clang.cindex.Cursor] = []\n",
                "    declarations_raw: set[str] = {}\n",
                "    tokens: list[clang.cindex.Token] = []\n",
                "    # Scan all direct symbols in root.\n",
                "    for child in root.get_children():\n",
                "        # print(f\"Scanning: {child.spelling}\")\n",
                "        node: clang.cindex.Cursor = child\n",
                "        kind: clang.cindex.CursorKind = node.kind\n",
                "        # Check if it is actually from the file.\n",
                "        if (\n",
                "            kind.is_declaration()\n",
                "            and node.storage_class == clang.cindex.StorageClass.NONE\n",
                "        ):\n",
                "            print(\n",
                "                f\"Found {node.spelling} [line={node.location.line}, col={node.location.column}]\"\n",
                "            )\n",
                "            tokens: clang.cindex.Token = node.get_tokens()\n",
                "            for token in tokens:\n",
                "                print(f\"  Token {token.spelling} {token.kind}\")\n",
                "            loc: clang.cindex.SourceRange = node.extent\n",
                "            end: clang.cindex.SourceLocation = loc.end\n",
                "            start: clang.cindex.SourceLocation = loc.start\n",
                "            print(\n",
                "                f\"Start: {start.offset}, End: {end.offset}, Range: {end.offset - start.offset}\"\n",
                "            )\n",
                "            print()\n",
                "            declarations.append(node)\n",
                "    return declarations\n",
                "\n",
                "\n",
                "index: clang.cindex.Index = clang.cindex.Index.create()\n",
                "tu: clang.cindex.TranslationUnit = index.parse(FILE)\n",
                "root: clang.cindex.Cursor = tu.cursor\n",
                "declarations: clang.cindex.Cursor = get_declarations_local(root)\n",
                "\n",
                "print(f\"Total {len(declarations)}\")\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Reversing Reach AST To Source Code\n",
                "\n",
                "The only issue I have found, multiple declarations in one statement need to be recognized and the nodes combined:\n",
                "\n",
                "```c\n",
                "int a, b;\n",
                "```\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Code for a:\n",
                        "```\n",
                        "int a\n",
                        "```\n",
                        "\n",
                        "Code for b:\n",
                        "```\n",
                        "int a, b\n",
                        "```\n",
                        "\n",
                        "Code for __VERIFIER_atomic_acquire():\n",
                        "```\n",
                        "void __VERIFIER_atomic_acquire(void)\n",
                        "{\n",
                        "    __VERIFIER_assume(a == 0);\n",
                        "    a = 1;\n",
                        "}\n",
                        "```\n",
                        "\n",
                        "Code for c(void *):\n",
                        "```\n",
                        "void *c(void *arg)\n",
                        "{\n",
                        "    ;\n",
                        "    __VERIFIER_atomic_acquire();\n",
                        "    b = 1;\n",
                        "    return NULL;\n",
                        "}\n",
                        "```\n",
                        "\n",
                        "Code for d:\n",
                        "```\n",
                        "pthread_t d\n",
                        "```\n",
                        "\n",
                        "Code for main():\n",
                        "```\n",
                        "int main()\n",
                        "{\n",
                        "    pthread_create(&d, 0, c, 0);\n",
                        "    __VERIFIER_atomic_acquire();\n",
                        "    if (!b)\n",
                        "        assert(0);\n",
                        "    return 0;\n",
                        "}\n",
                        "```\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "with open(FILE) as file:\n",
                "    source_code: str = file.read()\n",
                "\n",
                "\n",
                "def get_node_source_code(source_code: str, node: clang.cindex.Cursor) -> str:\n",
                "    loc: clang.cindex.SourceRange = node.extent\n",
                "    start: clang.cindex.SourceLocation = loc.start\n",
                "    end: clang.cindex.SourceLocation = loc.end\n",
                "    return source_code[start.offset : end.offset]\n",
                "\n",
                "\n",
                "for node in declarations:\n",
                "    print(f\"Code for {node.displayname}:\")\n",
                "    print(\"```\")\n",
                "    print(get_node_source_code(source_code, node))\n",
                "    print(\"```\")\n",
                "    print()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test Code\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from esbmc_ai.frontend.ast import ClangAST\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "__VERIFIER_atomic_acquire()\n",
                        "\n",
                        "<clang.cindex.Cursor object at 0x7fb7f421d520>\n",
                        "<clang.cindex.TranslationUnit object at 0x7fb7f5477c90>\n",
                        "c(arg: void *)\n",
                        "\n",
                        "<clang.cindex.Cursor object at 0x7fb7f421d5b0>\n",
                        "<clang.cindex.TranslationUnit object at 0x7fb7f5477c90>\n",
                        "main()\n",
                        "\n",
                        "<clang.cindex.Cursor object at 0x7fb7f421d6d0>\n",
                        "<clang.cindex.TranslationUnit object at 0x7fb7f5477c90>\n"
                    ]
                }
            ],
            "source": [
                "file = \"../samples/threading.c\"\n",
                "cast = ClangAST(file)\n",
                "functions = cast.get_fn_decl()\n",
                "\n",
                "for fn in functions:\n",
                "    print(str(fn) + \"\\n\")\n",
                "    # Seems like different cursors have the same translation unit...\n",
                "    print(fn.cursor)\n",
                "    print(fn.cursor.translation_unit)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test Code 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "struct linear {value: int}\n",
                        "typedef (LinearTypeDef) struct linear {struct linear: struct linear}\n",
                        "Point {x: int, y: int}\n",
                        "typedef (Point) Point {Point: Point}\n",
                        "enum Types {ONE: int, TWO: int, THREE: int}\n",
                        "typedef (Typest) enum Types {Types: enum Types}\n",
                        "union Combines {a: int, b: int, c: int}\n",
                        "typedef (CombinesTypeDef) union Combines {union Combines: union Combines}\n"
                    ]
                }
            ],
            "source": [
                "file = \"./samples/typedefs.c\"\n",
                "cast = ClangAST(file)\n",
                "functions = cast.get_type_decl()\n",
                "\n",
                "for fn in functions:\n",
                "    print(fn)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "#include \"/usr/include/stdlib.h\"\n",
                        "#include \"/usr/include/assert.h\"\n"
                    ]
                }
            ],
            "source": [
                "file = \"./samples/typedefs.c\"\n",
                "cast: ClangAST = ClangAST(file)\n",
                "includes = cast.get_include_directives()\n",
                "\n",
                "for include in includes:\n",
                "    print(include)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "esbmc-ai-awqrJrdH",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}